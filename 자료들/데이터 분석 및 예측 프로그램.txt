데이터 분석 및 예측 프로그램 

-선형 자료구조 예측을 중심으로 

모임 이름:미타찰 

모임원:박준범(소모임장), 한재영, 양승흠, 한결 

 

 

서론 

작년 정보수업시간에 데이터 분석 프로그램을 활용하여 데이터를 분석하는 방법에 대해 배운 적이 있습니다. 그때 당시엔 Orange라는 이름의 데이터 분석, 시각화, 머신러닝 프로그램을 사용하여 학습하였었습니다.   해당 프로그램은 코드를 사용하여 처음부터 만들어가는 것이 아닌 정해진 방식대로 데이터를 넣고 결과를 도출하는 프로그램 이였습니다. 그 프로그램을 통하여 저희는 데이터를 다루고, 자료를 분석하고, 기초적인 머신러닝을 수행하는 방식을 배울 수 있었습니다.  

 이후 2학년이 되어 소모임 주제를 생각하던 중 저희는 비록 원시적인 형태일지라도 데이터를 분석, 예측하는 프로그램을 저희 손으로 직접 만들어보면 어떨까 하는 생각을 하였습니다. 저희가 높은 정확도를 가지거나 전문적인 머신러닝을 수행하는 프로그램을 만들 수는 없겠지만 저희가 프로그램을 만들기 위하여 심도 있게 고민하고 정보를 찾는 과정이 모두 저희의 지식이 될 것이라 생각하였기에 이런 주제를 선정하여 활동을 진행하게 되었습니다. 

 

 

 

본론 

2-1. 기술의 정의 

빅 데이터란 거대한 규모의 데이터 집합에서 가치를 추출하고 결과를 분석하는 기술을 말합니다. 개인화되는 현대사회에서 그 가치가 갈수록 높아지는 기술임과 동시에 보안문제가 발생한다면 심각한 사생활침해가 발생할 수 있다는 비판 역시 존재합니다. 

예측 분석은 데이터 분석의 유형 중 하나로, 이름 그대로 현재 및 과거 데이터를 분석하여 미래 사건을 예측하는 분석 방법입니다. 예측 분석은 머신 러닝, 통계 모델링, 데이터 마이닝과 같은 분석 기술을 사용하여 조직이 트렌드, 행동, 향후 성과, 비즈니스 기회 등을 파악할 수 있도록 지원하고, 어떤 일이 발생할 가능성을 판단하는 데에 도움을 줍니다. 예측 분석은 인간, 기계가 쉽게 식별할 수 있도록 표준화된 형식을 가지는 정형 데이터, 식별 가능한 구조가 없는 비정형 데이터 모두에 적용할 수 있습니다.  

 예측분석의 일반적으로 먼저 대규모 데이터 세트의 패턴, 트렌드, 동작을 검색하는 프로세스인 데이터 마이닝에서 데이터 웨어하우스 또는 데이터 레이크와 같은 다양한 데이터베이스에서 데이터를 준비할 수 있도록 해줍니다. 이때 데이터 웨어하우스는 다양한 구조의 혹은 구조화되지 않는 데이터를 통일된 형식으로 변환하여 관리하는 데이터베이스를 의미하고, 데이터 레이크는 다양한 데이터를 공통된 형식 없이 원시데이터로 관리하는 데이터베이스를 의미합니다. 분석 준비가 완료되면 예측 모델링과정을 통해 예측 분석 모델을 구축하고 테스트하게 됩니다. 모델의 학습 및 평가를 거치고 나면 유사한 데이터에 관한 새로운 질문에 답하도록 나중에 재사용할 수도 있습니다. 한마디로, 데이터 분석, 머신러닝, 인공지능, 통계 모델 등을 사용하여 미래의 행동을 예측할 수 있는 패턴을 찾아 이전 데이터와 현재 데이터를 사용하여 미래에 대해 매우 정확하게 예측할 수 있게 해줍니다. 

 

 

 

2-2. 원리 

예측 분석은 데이터 과학자가 예측 모델을 사용하여 선택된 데이터 세트의 여러 요소 간의 상관관계를 식별하여 데이터 수집이 완료되면 통계 모델이 공식화되고, 학습되고, 수정된 후 예측을 생성합니다. 이를 정리하자면 아래와 같습니다. 

 

문제 정의: 먼저 사용자가 해결해야 하는 문제를 구분합니다. 

데이터 수집 및 구성: 데이터를 수집하여 데이터 흐름을 식별한 후 데이터 세트를 저장소에 구성합니다. 

데이터 사전 처리: 원시 데이터 자체는 명목적으로만 유용하기 때문에. 예측 분석 모델의 데이터를 준비하려면 데이터를 정제하여 입력 또는 측정 오류로 인한 이상치, 누락된 데이터 포인트, 극단적인 이상점을 제거해야 합니다. 

예측 모델 개발: 머신러닝, 회귀 모델, 결정 트리같은 예측 모델을 개발합니다. 

결과 검증: 모델의 정확성을 확인하고 결과에 따라 조정합니다. 

   

 

2-3. 데이터 분석 프로그램 구상 

일단 저희는 정해진 소량의 데이터 사이에서 관계를 인식하고 이를 바탕으로 근삿값을 예측 할 수 있는 데이터 분석 프로그램을 만들고자 하였습니다. 이 과정에서 저희가 구상을 설명하자면, A란 종류의 자료와 B란 종류의 자료가 있으며 그 자료의 값이 A1, A2 ...과 B1, B2 ...일 때. (A?-A평균)을 N?라고 하고 (B?-B평균)을 M?라고 할 때 둘 사이의 비례관계에서 A?가 평균에서 N?만큼 떨어졌을 때 B?는 평균에서 M?만큼 멀어졌으니 A?가 평균에서 1만큼 멀어지면 b?는 M?/N?만큼 멀어질 것이라고 생각하였습니다. 

 

 

2-4. 데이터분석 프로그램 제작 

이제 저희가 직접 만든 예측 분석 프로그램을 소개하겠습니다. 

 

def 변수입력(a,p):		#자료의 값을 입력받는 함수 

    a=list() 

    for i in range(1,p+1): 

        a.append(int(input())) 

    return a 

 

def 평균(k,a평균,k1,p):		#평균값을 구하는 함수 

    for i in range(0,k): 

        a평균=sum(k1)/p 

    return a평균 

 

#a값 

 

k=int(input("자료 가짓수(26이하);"))	#자료의 가짓수 입력 

p=int(input("자료 개수;"))			#자료의 개수 입력 

알파벳=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','v','z'] 

k1=list()		#자료의 값 저장- 2차원 배열 

for i in range(0,k): 

    print(알파벳[i]) 

    k1.append(변수입력(알파벳[i],p)) 

    print(k1[i]) 

 

 

#평균 

평균값=list()  

for i in range(0,k): 

    평균값.append(평균(k,알파벳[i]+'평균',k1[i],p)) 

print('평균값;',평균값) 

 

 

#편차 

n=list() 

m=list() 

for h in range(0,k): 

    for i in range(0,p): 

        n.append(k1[h][i]-평균값[h])#리스트n에 편차-1차원 배열 

    m.append(n[h*p:(h+1)*p])		#리스트m에 편차-2차원 배열 

print('n;',n) 

print('m;',m) 

 

 

#오류1-a의 편차가 0이 되는 경우-분모가 0이라 연산 불가 

while(int(m[0].count(0))>0): #기준자료a의 편차에 0이 있는지 확인 

    e=m[0].index(0)		#0이 있는 위치 e에 저장 

    el=list() 

    el.append(e)		#e의 값을 리스트el에 저장 

    for i in range(1,k): 	#기준 자료a제외 자료에서 확인 

        if (m[i][e]==0): 	#2가지 경우-0/0 

            m[0][e]=1		#임의로 a의 0인 편차에 1대입-추후 제외 

            m[i][e]=1 #임의로 a이외 다른 자료의 0인 편차에 1대입 

            r=list() 		#동일 위치 편차 사이 비율-m?/n?-일차원 

            R=list() 		#동일 위치 편차 사이 비율-m?/n?-이차원 

            for h in range(1,k):		#r에 값 입력 

                for j in range(0,p): 

                    r.append(m[h][j]/m[0][j]) 

                     

                R.append(r[(h-1)*p:h*p]) 		#R에 값 입력 

                Rm=sum(R[i-1])		#R의 값의 평균측정 

                R[i-1][e]=(Rm-1)/(p-1) #0/0인 경우 제외하고 계산 

        else :		#2가지 경우-실수/0 

            m[0][e]=1/3 #임의로 a의 0인 편차에 수치 대입-2차시 때  

            r=list() 		#동일 위치 편차 사이 비율-m?/n?-일차원 

            R=list() 		#동일 위치 편차 사이 비율-m?/n?-이차원 

            for h in range(1,k):		#r에 값 입력 

                for j in range(0,p): 

                    r.append(m[h][j]/m[0][j]) 

                R.append(r[(h-1)*p:h*p]) #R에 값 입력 

                Rm=sum(R[i-1]) #R의 값의 평균측정 

                R[i-1][e]=(Rm-1)/(p-1) 

#비율 

 

 

#출력 

print("k1=", k1) 

print("a;",k1[0]) 

for i in range(1,k): 

    print(알파벳[i],";",k1[i]) 

for i in range(0,k): 

    print(알파벳[i],"평균값;",평균값[i]) 

for i in range(0,k): 

    print(알파벳[i],"편차;",m[i]) 

print("a?,b? => a?가 a평균값에서 1 멀어질때 b?는 m?/n?의 평균 만큼 멀어진다") 

print("r;",r) 

print("R;",R) 

 

#예측 

 

 

for i in range(0,p): 

    at=int(input("test a;")) 

    for i in range(1,k): 

        print(알파벳[i],";",평균값[i]+(at-평균값[0])*sum(R[i-1])/5) 

 

 

 

2-6. 사용 예시 

예측 분석을 사용한 예시로는 사기 행위 감지, 전환 및 구매 예측. 기업의 운영 개선, 고객 세분화, 유지보수 예측에 사용됩니다. 

 대표적인 예시들을 들어보자면 Microsoft에선 GPS를 기반으로 사용자의 미래 위치를 예측하는 프로그램을 만들기도 하였고, Facebook의 경우 사용자가 관심을 가질 가능성이 높은 다른 사용자를 추천하는 기능을 가지고 있으며, Google의 경우 스팸메일을 예측하여 차단하는 프로그램을 

가지고 있습니다. 

 

 

한계 / 결론 / 소감 

한계 

수년 동안 지속되어 왔던 정보화와 특히 최근 발전하고 있는 메타버스에 따라서 인터넷 속 데이터양이 늘어나고 인공지능 기술이 발전하면서 예측분석은 더 넓은 범위에서 활용되며 우리의 삶에 영향을 미칠 것입니다. 하지만 예측분석에도 한계점은 있습니다. 기술자체의 좀 더 정확하게는 빅데이터를 사용하는 모든 기술의 공통적인 문제와 지금까지 인간이 쌓아온 데이터의 문제입니다. 빅데이터 기술의 문제는 너무 많은 데이터를 처리한다는 것입니다. 너무 많은 데이터는 개발자 본인도 자신이 만들 프로그램이 어떤 방식으로 데이터를 정리하고 판단하였는지 인식할 수 없습니다. 혹시나 데이터 처리과정에 개발자가 예측하지 못한 부분이 있을 수 있습니다. 그 예측되지 않은 부분이 데이터 처리 전체에서 명백한 변화를 준다면 그 프로그램의 오류를 인지할 수 있겠지만 소수의 집단에 한해서만 그 부분이 적용된다면 예측되지 않은 부분이 있다는 사실을 알기는 어렵습니다. 게다가 그 집단은 그로 인하여 부당한 평가를 받을 수 있습니다. 그리고 개발자가 셀 수 없이 많은 데이터 로그를 다시 하나하나 뜯어보게 할 능력이 없다면 즉 사회 상류층에 속하지 않는다면 이 부당함을 증명할 방법이 없습니다. 데이터의 문제는 지금까지 쌓아온 데이터가 인간의 행동에서 왔기에 인간의 편견을 그대로 반영한다는 것입니다. 예를 들어 ‘신용이 낮고 지인 중 범죄자가 있는 빈민가에 사는 흑인’은 사회적 편견에 의하여 대출을 받지 못할 가능성이 높고, 회사의 인사담당자들은 그를 채용하려 하지 않았을 것이며, 인근에서 일어난 범죄의 수사 대상이 되었을 수도 있습니다. 그리고 이 모든 것은 데이터가 되어 인공지능이 그러한 사람을 판단하는 기준이 됩니다. 즉 인공지능이 불평등을 학습하게 되는 것 입니다./ 

결론 

비록 이런 문제들이 있더라도 저희가 기술의 발전을 멈출 수는 없습니다. 기업이 본인들의 이익을 포기하지 않는다거나 하는 종류의 문제도 있지만 제가 생각했을 때 가장 큰 이유는 과거에 있었던 기술발전의 부작용 때문입니다. 과거의 기술발전이 만든 문제 즉 기후변화나 새로운 형태의 범죄 등을  해결하기 위해서 저희는 기술발전을 멈출 수 없다는 것입니다. 예를 들자면 빅 데이터 기술이 발전하여 전 지구적 범위의 데이터를 처리할 수 있게 된다면 기후변화나 환경오염에 훨씬 더 빠르게 대처할 수 있으며 예측분석은 문제해결의 우선순위나 문제 해결과정을 조직하는데 큰 도움이 됩니다. 게다가 빅 데이터는 도구적 기능을 하는 기술이니 만큼 대체에너지의 개발 같은 다른 기술의 발전에도 도운을 줍니다. 그러니 저희는 기술발전을 장려하면서 기술 발전 과정에서 새롭게 생겨날 문제들을 최소화하기 위하여 제도적, 기술적 방안을 동시에 준비해 나아가야 한다고 생각합니다./ 

소감 

박준범 

 

 

출처 

https://cloud.google.com/learn/what-is-predictive-analytics?hl=ko 

 

https://www.redhat.com/ko/topics/automation/how-predictive-analytics-improve-it-performance 

 

 

 